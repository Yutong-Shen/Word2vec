{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation with word analogy using tools from benchmarks repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr\n",
    "from scipy import spatial\n",
    "import numpy as np\n",
    "import logging\n",
    "from six import iteritems\n",
    "import pandas as pd\n",
    "from itertools import chain\n",
    "import argparse\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_path = 'E:/Word2vec/embeddings_wiki.npy'\n",
    "vocab_path = 'E:/Word2vec/vocab_300.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(vocab_path, encoding=\"utf8\") as f:\n",
    "    vocab = f.readlines()\n",
    "vocab = [w.strip() for w in vocab]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lookup_table(word):\n",
    "    return embed[vocab.index(word)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = np.load(embed_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from six import string_types, text_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Works just as good with unicode chars\n",
    "_delchars = [chr(c) for c in range(256)]\n",
    "_delchars = [x for x in _delchars if not x.isalnum()]\n",
    "_delchars.remove('\\t')\n",
    "_delchars.remove(' ')\n",
    "_delchars.remove('-')\n",
    "_delchars.remove('_')  # for instance phrases are joined in word2vec used this char\n",
    "_delchars = ''.join(_delchars)\n",
    "_delchars_table = dict((ord(char), None) for char in _delchars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_string(s, clean_words=True, lower=True, language=\"english\"):\n",
    "    \"\"\"\n",
    "    Ensures common convention across code. Converts to utf-8 and removes non-alphanumeric characters\n",
    "    Parameters\n",
    "    ----------\n",
    "    language: only \"english\" is now supported. If \"english\" will remove non-alphanumeric characters\n",
    "    lower: if True will lower strńing.\n",
    "    clean_words: if True will remove non alphanumeric characters (for instance '$', '#' or 'ł')\n",
    "    Returns\n",
    "    -------\n",
    "    string: processed string\n",
    "    \"\"\"\n",
    "\n",
    "    assert isinstance(s, string_types)\n",
    "\n",
    "    if not isinstance(s, text_type):\n",
    "        s = text_type(s, \"utf-8\")\n",
    "\n",
    "    if language == \"english\":\n",
    "        s = (s.lower() if lower else s)\n",
    "        s = (s.translate(_delchars_table) if clean_words else s)\n",
    "        return s\n",
    "    else:\n",
    "        raise NotImplementedError(\"Not implemented standarization for other languages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bunch(dict):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(Bunch, self).__init__(*args, **kwargs)\n",
    "        self.__dict__ = self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_google_analogy():\n",
    "    with open('E:/Word2vec/questions-words.txt', \"r\") as f:\n",
    "        L = f.read().splitlines()\n",
    "\n",
    "    # Simple 4 word analogy questions with categories\n",
    "    questions = []\n",
    "    answers = []\n",
    "    category = []\n",
    "    cat = None\n",
    "    for l in L:\n",
    "        if l.startswith(\":\"):\n",
    "            cat =l.lower().split()[1]\n",
    "        else:\n",
    "            words =  standardize_string(l).split()\n",
    "            questions.append(words[0:3])\n",
    "            answers.append(words[3])\n",
    "            category.append(cat)\n",
    "\n",
    "    assert set(category) == set(['gram3-comparative', 'gram8-plural', 'capital-common-countries',\n",
    "                                         'city-in-state', 'family', 'gram9-plural-verbs', 'gram2-opposite',\n",
    "                                         'currency', 'gram4-superlative', 'gram6-nationality-adjective',\n",
    "                                         'gram7-past-tense',\n",
    "                                         'gram5-present-participle', 'capital-world', 'gram1-adjective-to-adverb'])\n",
    "\n",
    "\n",
    "    syntactic = set([c for c in set(category) if c.startswith(\"gram\")])\n",
    "    category_high_level = []\n",
    "    for cat in category:\n",
    "         category_high_level.append(\"syntactic\" if cat in syntactic else \"semantic\")\n",
    "\n",
    "    # dtype=object for memory efficiency\n",
    "    return Bunch(X=np.vstack(questions).astype(\"object\"),\n",
    "                 y=np.hstack(answers).astype(\"object\"),\n",
    "                 category=np.hstack(category).astype(\"object\"),\n",
    "                 category_high_level=np.hstack(category_high_level).astype(\"object\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------ANALOGY----------\n",
      "Question: bangkok is to thailand as havana is to ?\n",
      "Answer: cuba\n",
      "Predicted:  plans\n",
      "Question: bangkok is to thailand as helsinki is to ?\n",
      "Answer: finland\n",
      "Predicted:  throughout\n",
      "Question: bangkok is to thailand as islamabad is to ?\n",
      "Answer: pakistan\n",
      "Predicted:  critical\n",
      "Question: bangkok is to thailand as kabul is to ?\n",
      "Answer: afghanistan\n",
      "Predicted:  part\n",
      "Question: bangkok is to thailand as london is to ?\n",
      "Answer: england\n",
      "Predicted:  australia\n",
      "Question: bangkok is to thailand as madrid is to ?\n",
      "Answer: spain\n",
      "Predicted:  spain\n",
      "Question: bangkok is to thailand as moscow is to ?\n",
      "Answer: russia\n",
      "Predicted:  post\n",
      "Question: bangkok is to thailand as oslo is to ?\n",
      "Answer: norway\n",
      "Predicted:  critical\n",
      "Question: bangkok is to thailand as ottawa is to ?\n",
      "Answer: canada\n",
      "Predicted:  australia\n",
      "Question: bangkok is to thailand as paris is to ?\n",
      "Answer: france\n",
      "Predicted:  france\n",
      "Question: bangkok is to thailand as rome is to ?\n",
      "Answer: italy\n",
      "Predicted:  italy\n",
      "Question: bangkok is to thailand as stockholm is to ?\n",
      "Answer: sweden\n",
      "Predicted:  republic\n",
      "Question: bangkok is to thailand as tehran is to ?\n",
      "Answer: iran\n",
      "Predicted:  orders\n",
      "Question: bangkok is to thailand as tokyo is to ?\n",
      "Answer: japan\n",
      "Predicted:  japan\n",
      "Question: bangkok is to thailand as athens is to ?\n",
      "Answer: greece\n",
      "Predicted:  throughout\n",
      "Question: bangkok is to thailand as baghdad is to ?\n",
      "Answer: iraq\n",
      "Predicted:  against\n",
      "Question: beijing is to china as berlin is to ?\n",
      "Answer: germany\n",
      "Predicted:  germany\n",
      "Question: beijing is to china as bern is to ?\n",
      "Answer: switzerland\n",
      "Predicted:  germany\n",
      "Question: beijing is to china as cairo is to ?\n",
      "Answer: egypt\n",
      "Predicted:  soviet\n",
      "Question: beijing is to china as canberra is to ?\n",
      "Answer: australia\n",
      "Predicted:  india\n",
      "Question: baku is to azerbaijan as dushanbe is to ?\n",
      "Answer: tajikistan\n",
      "Predicted:  squad\n",
      "Question: baku is to azerbaijan as funafuti is to ?\n",
      "Answer: tuvalu\n",
      "Predicted:  proceeds\n",
      "Question: baku is to azerbaijan as gaborone is to ?\n",
      "Answer: botswana\n",
      "Predicted:  basque\n",
      "Question: baku is to azerbaijan as georgetown is to ?\n",
      "Answer: guyana\n",
      "Predicted:  big\n",
      "Question: baku is to azerbaijan as hanoi is to ?\n",
      "Answer: vietnam\n",
      "Predicted:  vincent\n",
      "Question: baku is to azerbaijan as harare is to ?\n",
      "Answer: zimbabwe\n",
      "Predicted:  county\n",
      "Question: baku is to azerbaijan as havana is to ?\n",
      "Answer: cuba\n",
      "Predicted:  frequently\n",
      "Question: baku is to azerbaijan as helsinki is to ?\n",
      "Answer: finland\n",
      "Predicted:  device\n",
      "Question: baku is to azerbaijan as islamabad is to ?\n",
      "Answer: pakistan\n",
      "Predicted:  lee\n",
      "Question: baku is to azerbaijan as jakarta is to ?\n",
      "Answer: indonesia\n",
      "Predicted:  grown\n",
      "Question: baku is to azerbaijan as kabul is to ?\n",
      "Answer: afghanistan\n",
      "Predicted:  county\n",
      "Question: baku is to azerbaijan as kampala is to ?\n",
      "Answer: uganda\n",
      "Predicted:  patronised\n",
      "Question: baku is to azerbaijan as kathmandu is to ?\n",
      "Answer: nepal\n",
      "Predicted:  threat\n",
      "Question: bamako is to mali as bangkok is to ?\n",
      "Answer: thailand\n",
      "Predicted:  d\n",
      "Question: bamako is to mali as banjul is to ?\n",
      "Answer: gambia\n",
      "Predicted:  consolidated\n",
      "Question: bamako is to mali as beijing is to ?\n",
      "Answer: china\n",
      "Predicted:  lies\n",
      "Question: bamako is to mali as beirut is to ?\n",
      "Answer: lebanon\n",
      "Predicted:  floors\n",
      "Question: bamako is to mali as belgrade is to ?\n",
      "Answer: serbia\n",
      "Predicted:  cell\n",
      "Question: bamako is to mali as berlin is to ?\n",
      "Answer: germany\n",
      "Predicted:  mexico\n",
      "Question: rome is to italy as windhoek is to ?\n",
      "Answer: namibia\n",
      "Predicted:  africa\n",
      "Question: rome is to italy as yerevan is to ?\n",
      "Answer: armenia\n",
      "Predicted:  el\n",
      "Question: rome is to italy as zagreb is to ?\n",
      "Answer: croatia\n",
      "Predicted:  japan\n",
      "Question: rome is to italy as abuja is to ?\n",
      "Answer: nigeria\n",
      "Predicted:  japan\n",
      "Question: rome is to italy as accra is to ?\n",
      "Answer: ghana\n",
      "Predicted:  japan\n",
      "Question: rome is to italy as algiers is to ?\n",
      "Answer: algeria\n",
      "Predicted:  formed\n",
      "Question: rome is to italy as amman is to ?\n",
      "Answer: jordan\n",
      "Predicted:  al\n",
      "Question: rome is to italy as ankara is to ?\n",
      "Answer: turkey\n",
      "Predicted:  america\n",
      "Question: rome is to italy as antananarivo is to ?\n",
      "Answer: madagascar\n",
      "Predicted:  france\n",
      "Question: rome is to italy as apia is to ?\n",
      "Answer: samoa\n",
      "Predicted:  africa\n",
      "Question: rome is to italy as ashgabat is to ?\n",
      "Answer: turkmenistan\n",
      "Predicted:  france\n",
      "Question: rome is to italy as asmara is to ?\n",
      "Answer: eritrea\n",
      "Predicted:  martyrs\n",
      "Question: rome is to italy as astana is to ?\n",
      "Answer: kazakhstan\n",
      "Predicted:  southern\n",
      "Question: rome is to italy as athens is to ?\n",
      "Answer: greece\n",
      "Predicted:  europe\n",
      "Question: rome is to italy as baghdad is to ?\n",
      "Answer: iraq\n",
      "Predicted:  against\n",
      "Question: rome is to italy as baku is to ?\n",
      "Answer: azerbaijan\n",
      "Predicted:  parts\n",
      "Question: roseau is to dominica as santiago is to ?\n",
      "Answer: chile\n",
      "Predicted:  lives\n",
      "Question: roseau is to dominica as skopje is to ?\n",
      "Answer: macedonia\n",
      "Predicted:  friends\n",
      "Question: roseau is to dominica as sofia is to ?\n",
      "Answer: bulgaria\n",
      "Predicted:  american\n",
      "Question: roseau is to dominica as stockholm is to ?\n",
      "Answer: sweden\n",
      "Predicted:  black\n",
      "Question: comfortable is to uncomfortable as clear is to ?\n",
      "Answer: unclear\n",
      "Predicted:  here\n",
      "Question: competitive is to uncompetitive as consistent is to ?\n",
      "Answer: inconsistent\n",
      "Predicted:  clerks\n",
      "Question: competitive is to uncompetitive as convincing is to ?\n",
      "Answer: unconvincing\n",
      "Predicted:  moskva\n",
      "Question: competitive is to uncompetitive as convenient is to ?\n",
      "Answer: inconvenient\n",
      "Predicted:  ddc\n",
      "Question: competitive is to uncompetitive as decided is to ?\n",
      "Answer: undecided\n",
      "Predicted:  return\n",
      "Question: competitive is to uncompetitive as efficient is to ?\n",
      "Answer: inefficient\n",
      "Predicted:  unearth\n",
      "Question: competitive is to uncompetitive as ethical is to ?\n",
      "Answer: unethical\n",
      "Predicted:  diatribe\n",
      "Question: competitive is to uncompetitive as fortunate is to ?\n",
      "Answer: unfortunate\n",
      "Predicted:  exonerated\n",
      "Question: competitive is to uncompetitive as honest is to ?\n",
      "Answer: dishonest\n",
      "Predicted:  ripe\n",
      "Question: competitive is to uncompetitive as impressive is to ?\n",
      "Answer: unimpressive\n",
      "Predicted:  darjah\n",
      "Question: competitive is to uncompetitive as informative is to ?\n",
      "Answer: uninformative\n",
      "Predicted:  cain\n",
      "Question: competitive is to uncompetitive as informed is to ?\n",
      "Answer: uninformed\n",
      "Predicted:  daejeon\n",
      "Question: competitive is to uncompetitive as known is to ?\n",
      "Answer: unknown\n",
      "Predicted:  author\n",
      "Question: competitive is to uncompetitive as likely is to ?\n",
      "Answer: unlikely\n",
      "Predicted:  widely\n",
      "Question: competitive is to uncompetitive as logical is to ?\n",
      "Answer: illogical\n",
      "Predicted:  lifespan\n",
      "Question: competitive is to uncompetitive as pleasant is to ?\n",
      "Answer: unpleasant\n",
      "Predicted:  insignificance\n",
      "Question: competitive is to uncompetitive as possible is to ?\n",
      "Answer: impossible\n",
      "Predicted:  evidence\n",
      "Question: competitive is to uncompetitive as possibly is to ?\n",
      "Answer: impossibly\n",
      "Predicted:  retaliatory\n",
      "Question: competitive is to uncompetitive as productive is to ?\n",
      "Answer: unproductive\n",
      "Predicted:  erland\n",
      "Question: competitive is to uncompetitive as rational is to ?\n",
      "Answer: irrational\n",
      "Predicted:  morava\n",
      "Question: slow is to slowing as describe is to ?\n",
      "Answer: describing\n",
      "Predicted:  implications\n",
      "Question: slow is to slowing as discover is to ?\n",
      "Answer: discovering\n",
      "Predicted:  folke\n",
      "Question: slow is to slowing as enhance is to ?\n",
      "Answer: enhancing\n",
      "Predicted:  healed\n",
      "Question: slow is to slowing as fly is to ?\n",
      "Answer: flying\n",
      "Predicted:  documentary\n",
      "Question: slow is to slowing as generate is to ?\n",
      "Answer: generating\n",
      "Predicted:  moon\n",
      "Question: slow is to slowing as go is to ?\n",
      "Answer: going\n",
      "Predicted:  get\n",
      "Question: slow is to slowing as implement is to ?\n",
      "Answer: implementing\n",
      "Predicted:  throws\n",
      "Question: slow is to slowing as increase is to ?\n",
      "Answer: increasing\n",
      "Predicted:  increased\n",
      "Question: slow is to slowing as invent is to ?\n",
      "Answer: inventing\n",
      "Predicted:  salars\n",
      "Question: slow is to slowing as jump is to ?\n",
      "Answer: jumping\n",
      "Predicted:  janeiro\n",
      "Question: slow is to slowing as listen is to ?\n",
      "Answer: listening\n",
      "Predicted:  granulosa\n",
      "Question: slow is to slowing as look is to ?\n",
      "Answer: looking\n",
      "Predicted:  moon\n",
      "Question: slow is to slowing as move is to ?\n",
      "Answer: moving\n",
      "Predicted:  way\n",
      "Question: slow is to slowing as play is to ?\n",
      "Answer: playing\n",
      "Predicted:  win\n",
      "Question: slow is to slowing as predict is to ?\n",
      "Answer: predicting\n",
      "Predicted:  insensitive\n",
      "Question: slow is to slowing as read is to ?\n",
      "Answer: reading\n",
      "Predicted:  stated\n",
      "Question: slow is to slowing as run is to ?\n",
      "Answer: running\n",
      "Predicted:  ran\n",
      "Question: slow is to slowing as say is to ?\n",
      "Answer: saying\n",
      "Predicted:  stated\n",
      "Question: slow is to slowing as scream is to ?\n",
      "Answer: screaming\n",
      "Predicted:  wylie\n",
      "Question: slow is to slowing as see is to ?\n",
      "Answer: seeing\n",
      "Predicted:  so\n",
      "Questions correctly answered: 5 / 100\n"
     ]
    }
   ],
   "source": [
    "# Fetch analogy dataset\n",
    "data = fetch_google_analogy()\n",
    "\n",
    "word_embed = dict(zip(vocab, embed))\n",
    "\n",
    "print(\"----------ANALOGY----------\")\n",
    "\n",
    "# Pick a sample of data and calculate answers\n",
    "guessed = 0\n",
    "subset = list(chain(range(50, 70), range(1000, 1020), range(4000, 4020), range(10000, 10020),\n",
    "                      range(14000, 14020)))\n",
    "for id in subset:\n",
    "    w1, w2, w3 = data.X[id][0], data.X[id][1], data.X[id][2]\n",
    "    if w1 not in vocab or w2 not in vocab or w3 not in vocab:\n",
    "        continue\n",
    "    print(\"Question: {} is to {} as {} is to ?\".format(w1, w2, w3))\n",
    "    \n",
    "    print(\"Answer: \" + data.y[id])\n",
    "    s = lookup_table(w2) - lookup_table(w1) + lookup_table(w3)\n",
    "    best_match = 0.\n",
    "    best_index = 0\n",
    "\n",
    "    for i, (w, e) in enumerate(word_embed.items()):\n",
    "        if w == w1 or w == w2 or w == w3:\n",
    "            continue\n",
    "        cosine_sim = 1 - spatial.distance.cosine(s, e)\n",
    "        if cosine_sim >= best_match:\n",
    "            best_match = cosine_sim\n",
    "            best_index = i\n",
    "\n",
    "    print(\"Predicted: \", vocab[best_index])\n",
    "    if vocab[best_index] == data.y[id]:\n",
    "        guessed += 1\n",
    "\n",
    "print(\"Questions correctly answered: {} / {}\".format(guessed, len(subset)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
